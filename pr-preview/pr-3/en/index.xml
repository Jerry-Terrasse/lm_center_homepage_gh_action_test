<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hugo Academic CV Theme</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/</link><atom:link href="https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/index.xml" rel="self" type="application/rss+xml"/><description>Hugo Academic CV Theme</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en</language><lastBuildDate>Wed, 15 Jan 2025 00:00:00 +0000</lastBuildDate><image><url>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/media/icon_hu7729264130191091259.png</url><title>Hugo Academic CV Theme</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/</link></image><item><title>中国科学院学部“大模型/AIGC的健康发展与赋能赋智”科学与技术前沿论坛在南京召开</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/post/2024-01-16-healthy-development-and-empowerment-of-large-models-aigc/</link><pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/post/2024-01-16-healthy-development-and-empowerment-of-large-models-aigc/</guid><description>&lt;img src="image.png" width="100%" />
&lt;p>中国科学院学部第155次科学与技术前沿论坛—“大模型／AIGC的健康发展与赋能赋智”于2024年1月6－7日在南京召开。本次论坛由中国科学院学部主办，中国科学院学部学术与出版工作委员会、中国科学院信息技术科学部常务委员会承办，南京大学、东南大学和《中国科学》杂志社协办，中国科学院院士吕建、黄如和中国工程院院士王坚共同担任论坛主席。中国科学院学部学术与出版工作委员会主任包信和院士出席论坛，中国科学院学部工作局周德进、教育部教师工作司任友群、东南大学黄如院士、江苏省科技厅徐光辉出席论坛开幕式并致辞。包信和、吕建、黄如、谭铁牛、鄂维南、徐宗本等6位中国科学院院士，高文、杨善林等2位中国工程院院士，以及来自中国科学院、南京大学、东南大学、香港科技大学、科大讯飞、华为、阿里、小米、美的、吉利汽车研究院等87所高校、科研院所和企业的近300位专家参加了本次论坛，超过半数为45岁以下青年科学家。&lt;/p>
&lt;p>论坛分为主旨报告和专题报告两个环节，在主旨报告环节，谭铁牛院士介绍了生成式人工智能的发展态势，高文院士介绍了鹏城脑海预训练大模型底座与开源合作，杨善林院士介绍了AIGC及其科学基础，鄂维南院士介绍了深度学习的基本原理，徐宗本院士介绍了关于大模型的数理基础研究，英国皇家工程院院士、香港科技大学首席副校长郭毅可教授介绍了大模型的内涵科学问题，科大讯飞、华为、阿里的人工智能专家介绍了大模型的应用与创新实践。在专题报告环节，与会专家围绕“大模型／AIGC的发展前沿与协同创新”“大模型／AIGC助力科技发展”“大模型／AIGC助力实体经济”“大模型／AIGC助力教育变革”“大模型／AIGC与智能化基础软件”“大模型／AIGC与算力基础设施、及芯片技术”“大模型／AIGC安全可控、隐私保护与低成本部署”“大模型／AIGC的治理与管理”等8个专题进行了报告，报告结束后，与会专家学者还围绕专题进行圆桌提问交流。&lt;/p>
&lt;p>经过两天的交流研讨，与会专家就大模型与人工智能发展的关键技术与挑战、应用场景与产业赋能赋智、法律道德风险等进行了前瞻研讨，形成了一些初步共识，论坛结束后将以简报、专报等形式发布论坛成果。&lt;/p>
&lt;p>&lt;a href="http://ad.cas.cn/xbdt2022/202401/t20240116_5000694.html" target="_blank">查看原文&lt;/a>&lt;/p></description></item><item><title>中国科学院学部“大模型/AIGC的健康发展与赋能赋智”科学与技术前沿论坛在南京召开</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/post/2025-02-11-internvideo-25-release/</link><pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/post/2025-02-11-internvideo-25-release/</guid><description>&lt;img src="image.png" width="100%" />
&lt;p>中国科学院学部第155次科学与技术前沿论坛—“大模型／AIGC的健康发展与赋能赋智”于2024年1月6－7日在南京召开。本次论坛由中国科学院学部主办，中国科学院学部学术与出版工作委员会、中国科学院信息技术科学部常务委员会承办，南京大学、东南大学和《中国科学》杂志社协办，中国科学院院士吕建、黄如和中国工程院院士王坚共同担任论坛主席。中国科学院学部学术与出版工作委员会主任包信和院士出席论坛，中国科学院学部工作局周德进、教育部教师工作司任友群、东南大学黄如院士、江苏省科技厅徐光辉出席论坛开幕式并致辞。包信和、吕建、黄如、谭铁牛、鄂维南、徐宗本等6位中国科学院院士，高文、杨善林等2位中国工程院院士，以及来自中国科学院、南京大学、东南大学、香港科技大学、科大讯飞、华为、阿里、小米、美的、吉利汽车研究院等87所高校、科研院所和企业的近300位专家参加了本次论坛，超过半数为45岁以下青年科学家。&lt;/p>
&lt;p>论坛分为主旨报告和专题报告两个环节，在主旨报告环节，谭铁牛院士介绍了生成式人工智能的发展态势，高文院士介绍了鹏城脑海预训练大模型底座与开源合作，杨善林院士介绍了AIGC及其科学基础，鄂维南院士介绍了深度学习的基本原理，徐宗本院士介绍了关于大模型的数理基础研究，英国皇家工程院院士、香港科技大学首席副校长郭毅可教授介绍了大模型的内涵科学问题，科大讯飞、华为、阿里的人工智能专家介绍了大模型的应用与创新实践。在专题报告环节，与会专家围绕“大模型／AIGC的发展前沿与协同创新”“大模型／AIGC助力科技发展”“大模型／AIGC助力实体经济”“大模型／AIGC助力教育变革”“大模型／AIGC与智能化基础软件”“大模型／AIGC与算力基础设施、及芯片技术”“大模型／AIGC安全可控、隐私保护与低成本部署”“大模型／AIGC的治理与管理”等8个专题进行了报告，报告结束后，与会专家学者还围绕专题进行圆桌提问交流。&lt;/p>
&lt;p>经过两天的交流研讨，与会专家就大模型与人工智能发展的关键技术与挑战、应用场景与产业赋能赋智、法律道德风险等进行了前瞻研讨，形成了一些初步共识，论坛结束后将以简报、专报等形式发布论坛成果。&lt;/p>
&lt;p>&lt;a href="http://ad.cas.cn/xbdt2022/202401/t20240116_5000694.html" target="_blank">查看原文&lt;/a>&lt;/p></description></item><item><title>Large Language Model Research Group</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/llm/</link><pubDate>Fri, 01 Jan 1030 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/llm/</guid><description>&lt;h2 id="large-language-models-a-new-era-of-artificial-intelligence-in-language-understanding-and-generation">Large Language Models: A New Era of Artificial Intelligence in Language Understanding and Generation&lt;/h2>
&lt;p>&lt;strong>Large Language Models (LLMs)&lt;/strong> are one of the most groundbreaking technologies in the field of artificial intelligence in recent years. Trained on massive datasets, they are capable of understanding and generating natural language, demonstrating near-human-level performance in tasks such as text generation, translation, and question answering. This marks the dawn of a new era in artificial intelligence for language understanding and generation.&lt;/p>
&lt;h3 id="core-technological-breakthroughs">Core Technological Breakthroughs&lt;/h3>
&lt;p>The success of large language models is attributed to breakthroughs in the following key technologies:&lt;/p>
&lt;p>&lt;strong>In summary, large language models are profoundly transforming how we interact with machines and bringing unprecedented opportunities to various industries.&lt;/strong> With continuous technological advancements and expanding application scenarios, they will continue to drive progress in the field of artificial intelligence for language understanding and generation, creating more value for human society.&lt;/p></description></item><item><title>Multimodal Large Model Research Group</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/multimodal/</link><pubDate>Sat, 01 Jan 1020 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/multimodal/</guid><description/></item><item><title>Large Model Knowledge Enhancement Research Group</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/ke/</link><pubDate>Sun, 01 Jan 1015 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/ke/</guid><description>&lt;p>Large Model Knowledge Enhancement Research Group has been engaged in research on large model knowledge enhancement, code generation, and related fields. In the era of large models, our focus is on improving the models&amp;rsquo; capabilities in knowledge enhancement, reasoning, and multilingual understanding. We have conducted studies on foundation model knowledge enhancement and code large models.&lt;/p></description></item><item><title>Large Model Systems and Platforms Research Group</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/software-and-system/</link><pubDate>Mon, 01 Jan 1010 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/software-and-system/</guid><description>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-markdown" data-lang="markdown">&lt;span class="line">&lt;span class="cl">&lt;span class="gu">## Large Model Systems and Platforms: The Core Engine Driving the Scalable Application of Artificial Intelligence
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">With the rapid development of large model technology, efficiently training, deploying, and managing these massive models has become a critical challenge. &lt;span class="gs">**Large model systems and platforms**&lt;/span> have emerged to address this need, providing the infrastructure and toolchains necessary for the development and application of large-scale artificial intelligence models. They serve as the core engine driving the scalable application of AI.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">### Core Features and Capabilities
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Large model systems and platforms typically offer the following core functionalities:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">1.&lt;/span> &lt;span class="gs">**Distributed Training**&lt;/span>:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Supports distributed training for massive datasets and ultra-large models.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Provides efficient parallel computing and communication optimization, such as data parallelism, model parallelism, and pipeline parallelism.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Representative examples: Megatron-LM, DeepSpeed.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">2.&lt;/span> &lt;span class="gs">**Efficient Inference**&lt;/span>:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Optimizes inference for large models to reduce latency and resource consumption.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Supports model compression, quantization, and acceleration techniques.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Representative examples: TensorRT, ONNX Runtime.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">3.&lt;/span> &lt;span class="gs">**Model Management and Deployment**&lt;/span>:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Offers version control, monitoring, and updating capabilities for models.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Supports deployment across multiple environments, including cloud, edge, and devices.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Representative examples: MLflow, Kubeflow.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">4.&lt;/span> &lt;span class="gs">**Developer Tools and Ecosystem**&lt;/span>:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Provides user-friendly APIs, SDKs, and visualization tools.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Builds open developer communities and ecosystems.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">-&lt;/span> Representative examples: Hugging Face, OpenAI API.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">### Representative Platforms and Systems
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">The following are some notable large model systems and platforms:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> **Hugging Face**: Offers a rich collection of pre-trained models and datasets, supporting model training, fine-tuning, and deployment.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> **OpenAI API**: Provides powerful interfaces for large model services, enabling tasks like text generation and code generation.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> **DeepSpeed**: Developed by Microsoft, focuses on distributed training and optimization for large-scale models.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> **Colossal-AI**: Delivers efficient solutions for parallel training and inference, supporting ultra-large models.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">### Future Development Trends
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gu">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">The future development of large model systems and platforms will focus on the following directions:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">1.&lt;/span> &lt;span class="gs">**Performance Optimization**&lt;/span>: Further improves training and inference efficiency while reducing resource consumption.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">2.&lt;/span> &lt;span class="gs">**Usability Enhancement**&lt;/span>: Simplifies development processes and lowers the barrier to entry.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">3.&lt;/span> &lt;span class="gs">**Ecosystem Expansion**&lt;/span>: Builds a more open and thriving developer ecosystem.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">4.&lt;/span> &lt;span class="gs">**Security and Trustworthiness**&lt;/span>: Strengthens model security and explainability to ensure reliable applications.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">---
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="gs">**In summary, large model systems and platforms are the critical enablers for the practical application of large model technology.**&lt;/span> With continuous technological advancements and ecosystem improvements, they will provide stronger momentum for the scalable application of artificial intelligence, driving intelligent transformation across industries.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Large Model Systems and Platforms Research Group</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/system-and-platform/</link><pubDate>Mon, 01 Jan 1010 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/research/system-and-platform/</guid><description>&lt;p>The Large Model Systems and Platforms Research Group focuses on the construction of systems based on large models, large-scale training/inference deployment, and the application of large models. The group conducts research to address key challenges in efficient training, deployment, and the integration of domain knowledge into large models. In terms of applications, the group has a strong focus on reasoning tasks such as Automated Theorem Proving (ATP). In undergraduate education, the group offers courses on large model development, training students to build large models from scratch.&lt;/p></description></item><item><title>Jingwei Xu</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/jingwei-xu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/jingwei-xu/</guid><description/></item><item><title>Limin Wang</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/limin-wang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/limin-wang/</guid><description/></item><item><title>Shujian Huang</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/shujian-huang/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/shujian-huang/</guid><description/></item><item><title>Tong Lu</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/tong-lu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/tong-lu/</guid><description/></item><item><title>Wei Hu</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/wei-hu/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/wei-hu/</guid><description/></item><item><title>Wujun Li</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/wujun-li/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/wujun-li/</guid><description/></item><item><title>Yuan Yao</title><link>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/yuan-yao/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://Jerry-Terrasse.github.io/lm_center_homepage_gh_action_test/pr-preview/pr-3/en/author/yuan-yao/</guid><description/></item></channel></rss>